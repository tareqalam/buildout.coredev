#!/usr/bin/env python3
"""A concurrent wrapper for timing xmltestrunner tests for buildout.coredev."""
from argparse import ArgumentParser
from fnmatch import fnmatch
from itertools import cycle
from logging import Formatter
from logging import getLogger
from logging import INFO
from logging import StreamHandler
from logging.handlers import MemoryHandler
from multiprocessing import cpu_count
from multiprocessing import Pool
from os import access
from os import environ
from os import killpg
from os import path
from os import pathsep
from os import setpgrp
from os import unlink
from os import walk
from os import X_OK
from signal import SIGINT
from signal import SIGKILL
from signal import signal
from subprocess import check_output
from subprocess import DEVNULL
from subprocess import PIPE
from subprocess import Popen
from time import sleep
from time import time
import locale
import re
import sys


def which(program):
    def is_exe(fpath):
        return path.isfile(fpath) and access(fpath, X_OK)

    fpath, fname = path.split(program)
    if fpath:
        if is_exe(program):
            return program
    else:
        for dpath in environ["PATH"].split(pathsep):
            exe_file = path.join(dpath, program)
            if is_exe(exe_file):
                return exe_file

    return None


def humanize_time(seconds):
    """Humanize a seconds based delta time.

    Only handles time spans up to weeks for simplicity.
    """
    minutes, seconds = divmod(seconds, 60)
    hours, minutes = divmod(minutes, 60)
    days, hours = divmod(hours, 24)
    weeks, days = divmod(days, 7)

    seconds = int(seconds)
    minutes = int(minutes)
    hours = int(hours)
    days = int(days)
    weeks = int(weeks)

    output = []

    if weeks:
        quantifier = 'weeks' if weeks > 1 or weeks == 0 else 'week'
        output.append('{} {}'.format(weeks, quantifier))
    if days:
        quantifier = 'days' if days > 1 or days == 0 else 'day'
        output.append('{} {}'.format(days, quantifier))
    if hours:
        quantifier = 'hours' if hours > 1 or hours == 0 else 'hour'
        output.append('{} {}'.format(hours, quantifier))
    if minutes:
        quantifier = 'minutes' if minutes > 1 or minutes == 0 else 'minute'
        output.append('{} {}'.format(minutes, quantifier))

    quantifier = 'seconds' if seconds > 1 or seconds == 0 else 'second'
    output.append('{} {}'.format(seconds, quantifier))

    return ' '.join(output)


def setup_termination():
    # Set the group flag so that subprocesses will be in the same group.
    setpgrp()

    def terminate(signum, frame):
        # Kill the group (including main process) on terminal signal.
        killpg(0, SIGKILL)

    signal(SIGINT, terminate)


def discover_tests():
    logger.info('Discovering tests.')

    batches = {}
    layer = None
    classname = None
    for line in fetch_test_discovery_output(**DISCOVERY_PARAMS):
        if line.startswith('Listing'):
            layer = re.search('^Listing (.*) tests:', line).groups()[0]

        # All listed tests are indented with 2 spaces
        if layer and line.startswith('  '):
            if '(' in line:
                classname = re.search('.*\((.*)\).*', line).groups()[0]
            else:
                # Some doctests have a filename:testcase convention
                classname = re.search('([^:]*)', line).groups()[0].strip()

            # Count discovered tests per testclass
            if not batches.get(classname):
                batches[classname] = 0

            batches[classname] += 1

    return batches


def fetch_test_discovery_output(ENV=None, CMDLINE=None):
    env = environ.copy()

    if ENV:
        for key, value in ENV.items():
            env[key] = value

    output_encoding = sys.stdout.encoding

    if output_encoding is None:
        output_encoding = locale.getpreferredencoding()

    process = Popen(
        CMDLINE,
        env=env,
        stderr=DEVNULL,
        stdout=PIPE,
        )

    stdout = process.communicate()[0]
    return stdout.decode(output_encoding).splitlines()


def create_test_run_params():
    test_run_params = []
    port = 0

    for testclass, count in discover_tests().items():
        batch = {}
        batch['testclass'] = testclass
        batch['count'] = count
        batch['port'] = port
        test_run_params.append(batch)
        port += 1

    return tuple(sorted(
        test_run_params,
        key=lambda batch: -batch.get('count'),
        ))


def remove_bytecode_files(directory_path):
    logger.info('Removing bytecode files from %s', directory_path)

    for filename in find_bytecode_files(directory_path):
        unlink(filename)


def find_bytecode_files(directory_path):
    for root, _, files in walk(directory_path):
        for name in files:
            if fnmatch(name, '*.py[co]'):
                yield path.join(root, name)


def run_tests(test_run_params):
    params = ['bin/test']
    params.append('--all')
    params.append('--xml')

    testclass = test_run_params.get('testclass')
    count = test_run_params.get('count')
    port = test_run_params.get('port')

    if testclass:
        params.append('-t')
        params.append(testclass)

    env = environ.copy()

    if 'xvfb-run' in DISCOVERY_PARAMS['CMDLINE']:
        params = tuple(['xvfb-run', '-a'] + params)
        # Firefox > Chromium
        if which('geckodriver') or which('firefox'):
            env['ROBOT_BROWSER'] = 'firefox'
        elif which('chromedriver') or which('chromium'):
            env['ROBOT_BROWSER'] = 'chrome'

    printable_params = ' '.join(["'{}'".format(param) if ' ' in param else param for param in params])

    logger.info(
        "START - %s - %d %s",
        testclass,
        count,
        'test' if count == 1 else 'tests',
        )

    # Explicitly flush to trigger IPC over cPickle
    memory_handler.flush()

    # ZServer layers need unique ports
    env['ZSERVER_PORT'] = env.get('PORT{}'.format(port), str(55000 + port))

    start = time()

    process = Popen(
        params,
        env=env,
        stderr=PIPE,
        stdout=PIPE,
        )

    stdout, stderr = process.communicate()
    returncode = process.returncode

    runtime = time() - start

    result = {
        'testclass': testclass,
        'returncode': returncode,
        'runtime': runtime,
        'stderr': stderr,
        }

    return result


def handle_results(results):
    failed_tests = []
    unclean_stderr = []
    job_count = len(results)
    runtime = 0

    while results:
        sleep(1)

        mature_indices = []
        mature_results = []

        for i, result in enumerate(results):
            if result.ready():
                mature_indices.append(i)
                # The enumeration index can be off for the .pop() otherwise
                break

        for i in mature_indices:
            mature_results.append(results.pop(i).get())

        for result in mature_results:
            returncode = result.get('returncode', 1)
            stderr = result.get('stderr')
            runtime += result.get('runtime')

            if returncode:
                failed_tests.append(result.get('testclass'))

            if stderr:
                unclean_stderr.append(result.get('testclass'))

    error_count = len(failed_tests)

    if error_count:
        logger.error('%d / %d jobs failed.', error_count, job_count)

        for result in set(failed_tests):
            logger.error('Failures in %s', result)

    stderr_count = len(unclean_stderr)

    if stderr_count:
        logger.info('%d / %d jobs had an unclean STDERR.', stderr_count, job_count)

        for result in set(unclean_stderr):
            logger.info('Unclean STDERR in %s', result)

    logger.info(
        'Aggregate runtime %s.',
        humanize_time(runtime)
        )

    return len(failed_tests) == 0


def main():
    """Discovers and times tests in parallel via multiprocessing.Pool()."""
    # Remove *.py[co] files to avoid race conditions with parallel workers
    # stepping on each other's toes when trying to clean up stale bytecode.
    #
    # Setting PYTHONDONTWRITEBYTECODE is not enough, because running buildout
    # also already precompiles bytecode for some eggs.
    remove_bytecode_files(SOURCE_PATH)

    start = time()
    test_run_params = create_test_run_params()
    logger.info('Discovered tests in %s', humanize_time(time() - start))
    logger.info('Split the tests into %d jobs', len(test_run_params))
    logger.info('Running the jobs in up to %d processes in parallel', CONCURRENCY)

    # We need to explicitly flush here in order to avoid multiprocessing
    # related log output duplications due to picking inputs and globals as the
    # default IPC mechanism
    memory_handler.flush()

    start = time()

    pool = Pool(CONCURRENCY)

    results = []

    for params in test_run_params:
        # Alleviate cPickle load bursting for IPC
        sleep(0.25)
        results.append(pool.apply_async(run_tests, (params, )))

    success = handle_results(results)

    pool.close()
    pool.join()

    logger.info('Wallclock runtime %s.', humanize_time(time() - start))

    if success:
        logger.info('No failed tests.')
        return True

    return False


# Having the __main__ guard is necessary for multiprocessing.Pool().
if __name__ == '__main__':
    # Globals
    environ['PYTHONUNBUFFERED'] = '1'
    environ['PYTHONDONTWRITEBYTECODE'] = '1'

    CONCURRENCY = int(environ.get('MTEST_PROCESSORS', cpu_count()))
    BUILDOUT_PATH = path.abspath(path.join(__file__, '..', '..'))
    SOURCE_PATH = path.join(BUILDOUT_PATH, 'src')

    # CLI arguments
    parser = ArgumentParser(
        description='Run tests in parallel.',
        epilog='At least one of --dx or --robot is required. '
        'You must also have either chromedriver / chromium '
        'or geckodriver / firefox in your $PATH to run Robot tests.',
        )

    parser.add_argument(
        '--dx',
        action='store_true',
        help="Run Dexterity tests.",
        )

    parser.add_argument(
        '--robot',
        action='store_true',
        help="Run Robot tets.",
        )

    parser.add_argument(
        '-j',
        '--jobs',
        type=int,
        help='Set the testing concurrency level. '
        'Defaults to the number of threads.',
        )

    args = parser.parse_args()

    if not any((args.dx, args.robot, )):
        parser.print_help()
        exit(1)

    if args.jobs:
        CONCURRENCY = int(args.jobs)

    DISCOVERY_PARAMS = {}

    DISCOVERY_PARAMS = {}
    DISCOVERY_PARAMS['ENV'] = {'ROBOTSUITE_PREFIX':'ROBOT'}
    DISCOVERY_PARAMS['CMDLINE'] = ['bin/test', '--all', '--list-tests']

    if args.robot and not args.dx:
        DISCOVERY_PARAMS['CMDLINE'].extend(['-t', 'ROBOT'])
    elif args.dx and not args.robot:
        DISCOVERY_PARAMS['CMDLINE'].extend(['-t', '!ROBOT'])

    if args.robot:
        if which('geckodriver') or which('firefox'):
            DISCOVERY_PARAMS['ENV']['ROBOT_BROWSER'] = 'firefox'
        elif which('chromedriver') or which('chromium'):
            DISCOVERY_PARAMS['ENV']['ROBOT_BROWSER'] = 'chrome'

        if not DISCOVERY_PARAMS.get('ENV').get('ROBOT_BROWSER'):
            parser.print_help()
            exit(1)

        if which('xvfb-run'):
            DISCOVERY_PARAMS['CMDLINE'] = ['xvfb-run', '-a'].extend(DISCOVERY_PARAMS.get('CMDLINE'))

    DISCOVERY_PARAMS['CMDLINE'] = tuple(DISCOVERY_PARAMS['CMDLINE'])

    default_loglevel = INFO

    # Logging
    logger = getLogger('mtest')
    logger.setLevel(default_loglevel)

    # Set up logging to stdout
    stream_handler = StreamHandler()
    stream_handler.setLevel(default_loglevel)
    log_formatter = Formatter(
        ' - '.join((
            '%(asctime)s',
            '%(levelname)s',
            '%(message)s',
            )),
        )

    stream_handler.setFormatter(log_formatter)
    # Buffer log messages so we do not get broken-by-racecondition lines
    memory_handler = MemoryHandler(2, target=stream_handler)
    memory_handler.setLevel(default_loglevel)
    logger.addHandler(memory_handler)

    # Set up a separate logger for writing failure output to stdout. We do this
    # because the logging module handles I/O encoding properly, whereas with
    # 'print' we'd need to do it ourselves. (Think piping the output of
    # bin/mtest somewhere, or shell I/O redirection).
    log_output = getLogger('mtest.output')
    log_output.propagate = False
    stdout_handler = StreamHandler(stream=sys.stdout)
    stdout_handler.setFormatter(Formatter(''))
    log_output.addHandler(stdout_handler)
    log_output.setLevel(INFO)

    setup_termination()

    if args.robot:
        logger.info('Autodetected Robot browser: %s', DISCOVERY_PARAMS.get('ENV').get('ROBOT_BROWSER'))
        if 'xvfb-run' in DISCOVERY_PARAMS.get('CMDLINE'):
            logger.info("Using 'xvfb-run -a' to wrap the tests.")

    if main():
        exit(0)

    exit(1)
